{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script\n",
    "# NLP Technology - Assignment 2, Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "#### General imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports of other scripts\n",
    "\n",
    "Change to python scripts when less amendmends needed!\n",
    "-> new format will be e.g. from 1_DataImportAndConversion.ipynb import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%run PrecossesingWrapper.ipynb\n",
    "%run SVM.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'production': {'input': {'train': '../data/input/en_ewt-up-train_excerpt.conllu',\n",
       "   'test': '../data/input/en_ewt-up-test_excerpt.conllu'},\n",
       "  'intermediate': {},\n",
       "  'output': {}},\n",
       " 'sample': {'input': {'train': '../data/input/srl_univprop_en.example.conll',\n",
       "   'test': '../data/input/srl_univprop_en.test_example.conll'},\n",
       "  'intermediate': {},\n",
       "  'output': {}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dictionary with meta information\n",
    "\n",
    "'''\n",
    "\n",
    "Dictionary to carry all the relevant information for \n",
    "    - input, \n",
    "    - intermediate, and \n",
    "    - output files including their paths\n",
    "    \n",
    "    \n",
    "Possible execution modes:\n",
    "    - 'production'\n",
    "    - 'sample'\n",
    "    - 'custom'\n",
    "    \n",
    "'''\n",
    "\n",
    "executionMode_dict = {\n",
    "    'production' : {\n",
    "        'input' : {\n",
    "            'train' : '../data/input/en_ewt-up-train_excerpt.conllu',\n",
    "            'test'  : '../data/input/en_ewt-up-test_excerpt.conllu'\n",
    "        },\n",
    "        'intermediate': {\n",
    "            \n",
    "        },\n",
    "        'output': {\n",
    "            \n",
    "        }\n",
    "    },\n",
    "    'sample' : {\n",
    "        'input' : {\n",
    "            'train' : '../data/input/srl_univprop_en.example.conll',\n",
    "            'test'  : '../data/input/srl_univprop_en.test_example.conll'\n",
    "        },\n",
    "        'intermediate': {\n",
    "            \n",
    "        },\n",
    "        'output': {\n",
    "            \n",
    "        }\n",
    "    } \n",
    "}\n",
    "\n",
    "# use these parameters for now\n",
    "mode  = 'production'\n",
    "model = 'test' #'train'\n",
    "print_status = True\n",
    "\n",
    "\n",
    "#shows\n",
    "executionMode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_example = '../data/input/srl_univprop_en.example.conll'\n",
    "\n",
    "#path_train   = '../data/input/en_ewt-up-train.conllu' \n",
    "#path_test    = '../data/input/en_ewt-up-test.conllu'\n",
    "#path_dev     = '../data/input/en_ewt-up-dev.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#############################################\n",
      "#############################################\n",
      "#############################################\n",
      "#### Assignment 2.1                      ####\n",
      "#### Traditional Semantic Role Labeling  ####\n",
      "\n",
      "\n",
      "#######################\n",
      "#### Preprocessing ####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "StartTime=time.time()\n",
    "\n",
    "if print_status == True:\n",
    "    print(f'''\\n\\n\\n\\n\n",
    "#############################################\n",
    "#############################################\n",
    "#############################################\n",
    "#### Assignment 2.1                      ####\n",
    "#### Traditional Semantic Role Labeling  ####\n",
    "\n",
    "\n",
    "#######################\n",
    "#### Preprocessing ####\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Call runPreprocessing function on training dataset to preprocess training dataset\n",
    "-> use training = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "##################\n",
      "#### PRODUCTION ####\n",
      "\n",
      "\n",
      "#### 1 Data Import ####\n",
      " - # Sentences in file: 249\n",
      " - # Tokens in file: 5540\n",
      " - Maxium of columns in file: 26\n",
      "\n",
      "  - ## 250 sentences were added to dataframe.\n",
      " - Dataframe saved under: ../data/intermediate/production_train_01_importedData.csv\n",
      "\n",
      "\n",
      "#### 2 Predicate Prediction ####\n",
      " - completed\n",
      "\n",
      "\n",
      "#### 3 Data Conversion ####\n",
      " - # of lines in dataframe before conversion: 5540\n",
      " - # of lines in dataframe after conversion: 34633\n",
      " - completed\n",
      "\n",
      "\n",
      "#### 4 Feature Extraction ####\n",
      " Features extracted:\n",
      " - Constituents\n",
      " - Passive / Active\n",
      "\n",
      " - completed\n",
      "\n",
      "\n",
      "#### 5 Argument Identification ####\n",
      " - completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "executionMode_dict = runPreprocessing(executionMode_dict = executionMode_dict, \n",
    "                                      mode  = mode, \n",
    "                                      model = 'train', \n",
    "                                      print_status = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Call runPreprocessing function on training dataset to preprocess test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "##################\n",
      "#### PRODUCTION ####\n",
      "\n",
      "\n",
      "#### 1 Data Import ####\n",
      " - # Sentences in file: 49\n",
      " - # Tokens in file: 898\n",
      " - Maxium of columns in file: 27\n",
      "\n",
      "  - ## 50 sentences were added to dataframe.\n",
      " - Dataframe saved under: ../data/intermediate/production_test_01_importedData.csv\n",
      "\n",
      "\n",
      "#### 2 Predicate Prediction ####\n",
      " - completed\n",
      "\n",
      "\n",
      "#### 3 Data Conversion ####\n",
      " - # of lines in dataframe before conversion: 898\n",
      " - # of lines in dataframe after conversion: 5951\n",
      " - completed\n",
      "\n",
      "\n",
      "#### 4 Feature Extraction ####\n",
      " Features extracted:\n",
      " - Constituents\n",
      " - Passive / Active\n",
      "\n",
      " - completed\n",
      "\n",
      "\n",
      "#### 5 Argument Identification ####\n",
      " - completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "executionMode_dict = runPreprocessing(executionMode_dict = executionMode_dict, \n",
    "                                      mode  = mode, \n",
    "                                      model = 'test', \n",
    "                                      print_status = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'production': {'input': {'train': '../data/input/en_ewt-up-train_excerpt.conllu',\n",
       "   'test': '../data/input/en_ewt-up-test_excerpt.conllu'},\n",
       "  'intermediate': {'train': {'1_imported': '../data/intermediate/production_train_01_importedData.csv',\n",
       "    '2_predicatesPredicted': '../data/intermediate/production_train_02_predictedPredicates.csv',\n",
       "    '03_convertedDataframe': '../data/intermediate/production_train_03_convertedDataframe.csv',\n",
       "    '04_FeaturesExtracted': '../data/intermediate/production_train_04_ExtractedFeatures.csv',\n",
       "    '05_identifiedArguments': '../data/intermediate/production_train_05_identifiedArguments.csv'},\n",
       "   'test': {'1_imported': '../data/intermediate/production_test_01_importedData.csv',\n",
       "    '2_predicatesPredicted': '../data/intermediate/production_test_02_predictedPredicates.csv',\n",
       "    '03_convertedDataframe': '../data/intermediate/production_test_03_convertedDataframe.csv',\n",
       "    '04_FeaturesExtracted': '../data/intermediate/production_test_04_ExtractedFeatures.csv',\n",
       "    '05_identifiedArguments': '../data/intermediate/production_test_05_identifiedArguments.csv'}},\n",
       "  'output': {}},\n",
       " 'sample': {'input': {'train': '../data/input/srl_univprop_en.example.conll',\n",
       "   'test': '../data/input/srl_univprop_en.test_example.conll'},\n",
       "  'intermediate': {},\n",
       "  'output': {}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executionMode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Temporal Visual validation\\npath_to_input = '../data/intermediate/' + mode + '_' + model + '_05_identifiedArguments.csv'\\n\\ndf = pd.read_csv(path_to_input)\\nprint(df.shape)\\ndf.head(50)\\ndf.tail(50)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test \n",
    "'''# Temporal Visual validation\n",
    "path_to_input = '../data/intermediate/' + mode + '_' + model + '_05_identifiedArguments.csv'\n",
    "\n",
    "df = pd.read_csv(path_to_input)\n",
    "print(df.shape)\n",
    "df.head(50)\n",
    "df.tail(50)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "#### Classification ####\n",
      "\n",
      "\n",
      "#### 6 Argument classification ####\n",
      " - completed\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\n\\n\\n########################')\n",
    "print('#### Classification ####')\n",
    "\n",
    "executionMode_dict = classifyArguments(executionMode_dict = executionMode_dict, \n",
    "                                      mode  = mode, \n",
    "                                      print_status = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "#### Evaluation ####\n",
      "      Unnamed: 0  precision    recall  f1-score    support\n",
      "0           ARG0   0.375000  1.000000  0.545455   3.000000\n",
      "1           ARG1   1.000000  0.500000  0.666667   8.000000\n",
      "2           ARG2   0.000000  0.000000  0.000000   3.000000\n",
      "3       ARGM-DIS   0.000000  0.000000  0.000000   1.000000\n",
      "4       ARGM-LOC   0.000000  0.000000  0.000000   0.000000\n",
      "5       ARGM-MNR   0.000000  0.000000  0.000000   1.000000\n",
      "6       ARGM-NEG   0.000000  0.000000  0.000000   0.000000\n",
      "7       ARGM-TMP   0.000000  0.000000  0.000000   1.000000\n",
      "8              _   1.000000  0.500000  0.666667   2.000000\n",
      "9       accuracy   0.421053  0.421053  0.421053   0.421053\n",
      "10     macro avg   0.263889  0.222222  0.208754  19.000000\n",
      "11  weighted avg   0.585526  0.421053  0.437002  19.000000\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\n\\n\\n####################')\n",
    "print('#### Evaluation ####')\n",
    "\n",
    "\n",
    "path_to_report = executionMode_dict[mode]['output']['classifiedArgumentsReport']\n",
    "report = pd.read_csv(path_to_report)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time:  14.8  min\n"
     ]
    }
   ],
   "source": [
    "TotalTime=time.time() - StartTime\n",
    "print('Total Time: ', np.round(TotalTime/60, 2), ' min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

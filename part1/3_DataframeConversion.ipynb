{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Dataframe Conversion\n",
    "\n",
    "This script provides a function that converts the dataframe in a sense that each sentence is duplicated as often as the maximum of predicted or actual predicates per sentence <br>\n",
    "\n",
    "\n",
    "*Input:*  \n",
    "- executionMode_dict\n",
    "- mode               -> ('production' / 'sample')\n",
    "- model              -> ('train' / 'test')\n",
    "- print_status       -> (True / False)\n",
    "- sentence_limit = None  (limit of sentences to import (default: None)\n",
    "\n",
    "*Output:* \n",
    "- executionMode_dict \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions for transformation of dataframe\n",
    "\n",
    "# helper function to combine predicate arrays\n",
    "# input value of predicate_gold and predicate_predicted. if either one is true, return true\n",
    "# -> applied via lambda function to each row in respective dataframe containing one sentence\n",
    "# -> goal is to have a boolean array that dictates the amount of needed repetitions of sentence  \n",
    "#    and at which index to look for predicate\n",
    "def findPredicateUnion(predicateGold, predicatePredicted):\n",
    "    if predicateGold != '_' or predicatePredicted == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### function to retrieve arguments\n",
    "\n",
    "def convertDataframe(executionMode_dict,\n",
    "                     mode,                   #('production' / 'sample')\n",
    "                     model,                  #('train' / 'test')\n",
    "                     print_status   = False,\n",
    "                     sentence_limit = None):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    '''\n",
    "    dataframe structure information:\n",
    "    \n",
    "    input:  a dataframe containing the following columns:\n",
    "                ['sentenceId', \n",
    "                 'id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space', \n",
    "                 'predicate', 'label', '_', '_', ... '_', \n",
    "                 'predicate_prediction']\n",
    "\n",
    "                 -> note that \n",
    "                    - predicate_prediction has to be created beforehand\n",
    "                    - a variable amount of '_' columns is possible\n",
    "                    \n",
    "\n",
    "    output: the expanded dataframe dataframe containing the following columns\n",
    "                ['sentenceId', 'sentenceRepetition', \n",
    "                 'id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space',\n",
    "                 'predicate_prediction', 'label_ident_prediction', 'label_prediction',\n",
    "                 'predicate_gold', 'label_ident_gold', 'label_gold']\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    path_to_input = executionMode_dict[mode]['intermediate'][model]['2_predicatesPredicted']\n",
    "    path_to_save = '../data/intermediate/' + mode + '_' + model +'_03_convertedDataframe.csv'\n",
    "    executionMode_dict[mode]['intermediate'][model]['03_convertedDataframe'] = path_to_save\n",
    "    \n",
    "    \n",
    "    if print_status == True:    \n",
    "        print('\\n\\n#### 3 Data Conversion ####')\n",
    "    \n",
    "    \n",
    "    # read dataframe in\n",
    "    df = pd.read_csv(path_to_input)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # taken from 01_dataImport\n",
    "    conll_header_adapted = ['sentenceId', 'id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space', 'predicate', 'label']\n",
    "    \n",
    "\n",
    "    ## prepare a dataframe to store all conversions in\n",
    "    # basic features\n",
    "    df_expanded = pd.DataFrame(columns=conll_header_adapted[:-2])\n",
    "    # + these four additional columns, we want to add\n",
    "    df_expanded['predicate_gold']       = False #np.nan\n",
    "    df_expanded['label_gold']           = '_'   #np.nan\n",
    "    df_expanded['predicate_prediction'] = False #np.nan\n",
    "    df_expanded['sentenceRepetition']   = 0\n",
    "\n",
    "    df_expanded_columns = df_expanded.columns\n",
    "\n",
    "    ## do conversion\n",
    "\n",
    "    # loop through sentences\n",
    "    for s_id in df.sentenceId.unique():\n",
    "\n",
    "        # filter for only this sentence\n",
    "        df_sentence = df[df.sentenceId == s_id].copy()   # remove hardcoing of sentence 2 (equivalent to index 1) as example\n",
    "\n",
    "        # count rows for which predicate_gold is true (actually != '_') OR predicate_predicted is true\n",
    "        df_sentence['union_predicates_gold_predicted'] = df.apply(lambda x: findPredicateUnion(x.predicate, x.predicate_prediction), axis=1)\n",
    "\n",
    "\n",
    "        # return indices of rows with label True of the columns of the predicates\n",
    "        indices_union     = np.where(np.array(df_sentence.union_predicates_gold_predicted) == True)[0]\n",
    "        indices_gold      = np.where(np.array(df_sentence.predicate)                       != '_' )[0]\n",
    "        indices_predicted = np.where(np.array(df_sentence.predicate_prediction)            == True)[0]\n",
    "\n",
    "\n",
    "        #nr_of_predicates = df_sentence.union_predicates_gold_predicted[df_sentence.union_predicates_gold_predicted == True].count()\n",
    "        nr_of_predicates = len(indices_union)\n",
    "\n",
    "\n",
    "        # loop through nr_of_predicates\n",
    "        for i in range(nr_of_predicates):\n",
    "\n",
    "\n",
    "            # create new copy for working with within this repetition of sentence\n",
    "            df_sentence_repetition = df_sentence.copy()\n",
    "\n",
    "\n",
    "            ### fill values for new important columns\n",
    "\n",
    "            # id for repition of sentence to be able to loop through afterwards\n",
    "            df_sentence_repetition['sentenceRepetition']   = i\n",
    "\n",
    "\n",
    "            ## predicates\n",
    "\n",
    "            # fill predicate columns with False as default \n",
    "            # -> afterwards only replace that one specific row with True, which we look at in this repitition\n",
    "            predicate_array_gold   = np.full(len(df_sentence_repetition), False)\n",
    "            predicate_array_pred   = np.full(len(df_sentence_repetition), False)\n",
    "\n",
    "            # now replace respective index of predicate columns if it is also in the respective column\n",
    "            if indices_union[i] in indices_gold:\n",
    "                predicate_array_gold[indices_union[i]] = True\n",
    "            if indices_union[i] in indices_predicted:\n",
    "                predicate_array_pred[indices_union[i]] = True\n",
    "\n",
    "            # assign created arrays to dataframe\n",
    "            df_sentence_repetition['predicate_gold']       = predicate_array_gold\n",
    "            df_sentence_repetition['predicate_prediction'] = predicate_array_pred\n",
    "\n",
    "\n",
    "\n",
    "            ## labels\n",
    "\n",
    "            # -> transform labels from all label columns to this one column\n",
    "\n",
    "            # create filler array\n",
    "            label_array = np.full(len(df_sentence_repetition), '_')\n",
    "\n",
    "            # slice df_sentence\n",
    "            row = df_sentence.iloc[indices_union[i], :]\n",
    "            list_of_column_indices_with_V = np.where(np.array(row) == 'V')[0]\n",
    "\n",
    "            # sanity check -> columns found with V should be 1\n",
    "            if len(list_of_column_indices_with_V) == 1:\n",
    "\n",
    "                # do conversion\n",
    "\n",
    "                # find respective_label_column\n",
    "                respective_column_index = list_of_column_indices_with_V[0]\n",
    "\n",
    "                # retrieve column\n",
    "                respective_label_column = np.array(df_sentence.iloc[:, respective_column_index])\n",
    "\n",
    "                # replave 'V' label with '_'\n",
    "                respective_label_column[respective_label_column == 'V'] = '_'\n",
    "\n",
    "                # overwrite filler with retrieved labels\n",
    "                label_array = respective_label_column\n",
    "\n",
    "            # label_array remains only filled with '_' because no (coherent) labels could be found\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # assign retrieved array\n",
    "            df_sentence_repetition['label_gold']        = label_array\n",
    "\n",
    "\n",
    "\n",
    "            ### \"postprocessing\"\n",
    "\n",
    "            # drop unneccessary columns \n",
    "            # search for all headers with 'label' in it\n",
    "            l = df_sentence_repetition.columns\n",
    "            columns_to_drop = list(l[[True if 'label' in x else False for x in l]])\n",
    "            columns_to_drop.remove('label_gold')\n",
    "            columns_to_drop.append('predicate')\n",
    "            columns_to_drop.append('union_predicates_gold_predicted')\n",
    "            #df_sentence_repetition = df_sentence_repetition.drop(labels=['_', 'label', 'predicate', 'union_predicates_gold_predicted'], axis=1)\n",
    "            df_sentence_repetition = df_sentence_repetition.drop(labels=columns_to_drop, axis=1)\n",
    "            \n",
    "            # concatenate to large dataframe\n",
    "            df_expanded = pd.concat([df_expanded, df_sentence_repetition], axis = 0, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### insert general columns for later use\n",
    "\n",
    "    # for later insert of predicted label in in classification task\n",
    "    df_expanded['label_prediction']       = np.nan \n",
    "\n",
    "    # for prediction of label identification\n",
    "    df_expanded['label_ident_prediction'] = np.nan\n",
    "\n",
    "    # gold of label identification (true/false)\n",
    "    df_expanded['label_ident_gold']       = df_expanded.label_gold.apply(lambda x: True if x != '_' else False)\n",
    "\n",
    "    #reordering columns\n",
    "    df_expanded = df_expanded[['sentenceId', 'sentenceRepetition', \n",
    "                'id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space', \n",
    "                'predicate_prediction', 'label_ident_prediction', 'label_prediction', \n",
    "                'predicate_gold',       'label_ident_gold',       'label_gold']]\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    #write dataframe out\n",
    "    df_expanded.to_csv(path_to_save, index=False)\n",
    "    \n",
    "    if print_status == True:\n",
    "        \n",
    "        print(f' - # of lines in dataframe before conversion: {len(df)}')\n",
    "        print(f' - # of lines in dataframe after conversion: {len(df_expanded)}')\n",
    "        print( ' - completed')\n",
    "\n",
    "    return executionMode_dict\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

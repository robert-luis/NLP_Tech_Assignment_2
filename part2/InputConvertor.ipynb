{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Input Conll to json file\n",
    "\n",
    "This script converts the input file (already read in as dataframe) into the json input for the neural SRL scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_to_input = '../data/intermediate/sample_train_01_importedData.csv'\n",
    "    \n",
    "# read dataframe in\n",
    "df = pd.read_csv(path_to_input)\n",
    "\n",
    "# list to append dicts as json element\n",
    "x = []\n",
    "\n",
    "\n",
    "\n",
    "## do conversion\n",
    "\n",
    "# loop through sentences\n",
    "for s_id in df.sentenceId.unique():\n",
    "\n",
    "    # filter for only this sentence\n",
    "    df_sentence = df[df.sentenceId == s_id].copy()   \n",
    "\n",
    "    # return indices of rows with label True of the columns of the predicates\n",
    "    indices_gold      = np.where(np.array(df_sentence.predicate) != '_' )[0]\n",
    "\n",
    "    nr_of_predicates = len(indices_gold)\n",
    "\n",
    "    \n",
    "    # loop through nr_of_predicates\n",
    "    for i in range(nr_of_predicates):\n",
    "\n",
    "        # create new dict as json element\n",
    "        elem = {}\n",
    "        seq_words  = []\n",
    "        bio        = []\n",
    "        pred_sense = []\n",
    "        \n",
    "        \n",
    "        # create new copy for working with within this repetition of sentence\n",
    "        df_sentence_repetition = df_sentence.copy()\n",
    "\n",
    "        # retrieve token forms\n",
    "        seq_words  = list(df_sentence_repetition.form)\n",
    "        \n",
    "        # assign pred_sense\n",
    "        pred_sense.append(int(indices_gold[i]))\n",
    "        pred_sense.append(np.array(df_sentence_repetition.predicate)[indices_gold[i]])\n",
    "        pred_sense.append('_')\n",
    "        pred_sense.append(np.array(df_sentence_repetition.xpos)[indices_gold[i]])\n",
    "    \n",
    "    \n",
    "        ## labels\n",
    "\n",
    "        # -> transform labels from all label columns to this one column\n",
    "\n",
    "        # create filler array\n",
    "        label_array = np.full(len(df_sentence_repetition), '0')\n",
    "\n",
    "        # slice df_sentence\n",
    "        row = df_sentence.iloc[indices_gold[i], :]\n",
    "        list_of_column_indices_with_V = np.where(np.array(row) == 'V')[0]\n",
    "\n",
    "        # sanity check -> columns found with V should be 1\n",
    "        if len(list_of_column_indices_with_V) == 1:\n",
    "\n",
    "            # do conversion\n",
    "\n",
    "            # find respective_label_column\n",
    "            respective_column_index = list_of_column_indices_with_V[0]\n",
    "\n",
    "            # retrieve column\n",
    "            respective_label_column = np.array(df_sentence.iloc[:, respective_column_index])\n",
    "\n",
    "            # replave '_' label with '0'\n",
    "            respective_label_column[respective_label_column == '_'] = '0'\n",
    "\n",
    "            # overwrite filler with retrieved labels\n",
    "            label_array = respective_label_column\n",
    "\n",
    "        # label_array remains only filled with '_' because no (coherent) labels could be found\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # assign retrieved array\n",
    "        #df_sentence_repetition['label_gold']        = label_array\n",
    "        for i in range(len(label_array)):\n",
    "            if label_array[i] != '0':\n",
    "                label_array[i] = 'B-' + label_array[i]\n",
    "                \n",
    "\n",
    "        bio = list(label_array)\n",
    "        \n",
    "        \n",
    "        elem[\"seq_words\"]  = seq_words\n",
    "        elem[\"BIO\"]        = bio\n",
    "        elem[\"pred_sense\"] = pred_sense\n",
    "        \n",
    "        \n",
    "        # append list of elements\n",
    "        x.append(elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(x, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/intermediate/neuralSRL_sample_train_input.json', 'w') as outfile:\n",
    "    outfile.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
